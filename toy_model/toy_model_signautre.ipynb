{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#toy model bayesian signature inference\n",
    "\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist \n",
    "from torch.distributions import constraints\n",
    "import numpy as np\n",
    "from pyro.optim import Adam\n",
    "\n",
    "\n",
    "#define the model in terms of M = phylogenetic matrix ,K = number of signatures besides the aging signatures SBS1,SBS5.\n",
    "# The aging signatures are described by the fixed matrix Beta_aging. Beta_aging has dim (2,96).\n",
    "# In this toy model the rows of M are rank 96 vectors M_truncal,M_plus,M_mignus. M_truncal contains shared mutations,\n",
    "# M_plus,M_mignus contain the private mutations of two distinct subpopulations. We call t_0 the split time between the two \n",
    "# subpopulations, t_1 and t_2 the MRCA times of the two branches. Times are measured in terms of number of mutations.\n",
    "# the overlaps between the two branches starting at t_0 is overlap = min(t_2,t_1). \n",
    "# The overap of the truncal branch with the others is clearly 0. So we define overlaps as the 3X3 overlap symmetric matrix\n",
    "\n",
    "def model(M, K, Beta_aging, overlaps):\n",
    "    \n",
    "    num_sumples = 3\n",
    "    \n",
    "    # construct covariance matrix for alpha sampling with RBF-like kernel\n",
    "    \n",
    "    cov = torch.zeros(num_samples*(K+2),num_samples*(K+2))\n",
    "    \n",
    "    for i in range(num_samples*(K+2)):\n",
    "        \n",
    "        for j in range(num_samples*(K+2)):\n",
    "            \n",
    "            if i==j : cov[i,j] = 1     \n",
    "                \n",
    "                # correlation structure : we correlate activities of the same signature \n",
    "                # according to phylogenetic tree\n",
    "                \n",
    "            elif  (i != j) and ((j-i)%(K + 2) == 0) : \n",
    "                \n",
    "                m = int(i/(K+2))\n",
    "                n = int(j/(K+2))\n",
    "                \n",
    "                cov[i,j] = np.heaviside(overlaps[m,n], 0)*np.exp(-1/( 1 + overlaps[m,n]))\n",
    "                \n",
    "            else: cov[i,j] = 0\n",
    "    \n",
    "      #sample phylogeny activities as a 3*(K+2) vector from multivariate Lognormal\n",
    "    \n",
    "    log_alpha = pyro.sample(\"activities\", dist.MultivariateNormal(torch.zeros(num_samples*(K+2)),cov))\n",
    "    \n",
    "    # sample the extra signature profiles\n",
    "    \n",
    "    with pyro.plate(\"signal samplig\", K):\n",
    "    \n",
    "        Beta_signals = pyro.sample(\"extra_signal\", dist.Dirichlet(torch.ones(96)))    \n",
    "        \n",
    "        \n",
    "   # write the likelihood\n",
    "\n",
    "\n",
    "    with pyro.plate(\"context\",96):\n",
    "        \n",
    "        with pyro.plate(\"sample\",num_samples):\n",
    "    \n",
    "            pyro.sample(\"obs\", dist.Poisson(torch.matmul(torch.exp(log_alpha.reshape(num_samples,K+2)),\n",
    "                                                         torch.cat((Beta_aging,Beta_signals),0))),obs=M)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the guide. We perform a MAP estimate\n",
    "\n",
    "from pyro.infer.autoguide import AutoDelta\n",
    "from pyro.infer.autoguide.initialization import init_to_sample\n",
    "\n",
    "guide = AutoDelta(model,init_loc_fn = init_to_sample)\n",
    "    \n",
    "    \n",
    "    \n",
    "# SVI\n",
    "\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "\n",
    "\n",
    "\n",
    "def inference(model,guide,M,K,overlaps,Beta_aging,lr=0.05,num_steps=500):\n",
    "\n",
    "    pyro.clear_param_store()  # always clear the store before the inference\n",
    "\n",
    "    # learning global parameters\n",
    "\n",
    "    adam_params = {\"lr\": lr}\n",
    "    optimizer = Adam(adam_params)\n",
    "    elbo = Trace_ELBO()\n",
    "\n",
    "    svi = SVI(model, guide, optimizer, loss=elbo)\n",
    "\n",
    "#    inference\n",
    "\n",
    "#   do gradient steps\n",
    "\n",
    "    for step in range(num_steps):\n",
    "        loss = svi.step(M, K,Beta_aging,overlaps)  # get the loss function after a gradient step\n",
    "        if step % 10 == 0:\n",
    "            print(\"loss=\", loss)  # check the progress\n",
    "\n",
    "    print(\"final loss=\", svi.evaluate_loss(M, K,Beta_aging,overlaps)) \n",
    "\n",
    "       #get MAP estimates\n",
    " \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example inference\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "X_1 = pd.read_csv(\"/Users/riccardobergamin/sample_1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>A[C&gt;A]A</th>\n",
       "      <th>A[C&gt;A]C</th>\n",
       "      <th>A[C&gt;A]G</th>\n",
       "      <th>A[C&gt;A]T</th>\n",
       "      <th>A[C&gt;G]A</th>\n",
       "      <th>A[C&gt;G]C</th>\n",
       "      <th>A[C&gt;G]G</th>\n",
       "      <th>A[C&gt;G]T</th>\n",
       "      <th>A[C&gt;T]A</th>\n",
       "      <th>...</th>\n",
       "      <th>T[T&gt;A]G</th>\n",
       "      <th>T[T&gt;A]T</th>\n",
       "      <th>T[T&gt;C]A</th>\n",
       "      <th>T[T&gt;C]C</th>\n",
       "      <th>T[T&gt;C]G</th>\n",
       "      <th>T[T&gt;C]T</th>\n",
       "      <th>T[T&gt;G]A</th>\n",
       "      <th>T[T&gt;G]C</th>\n",
       "      <th>T[T&gt;G]G</th>\n",
       "      <th>T[T&gt;G]T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRMA_1 clonal</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRMA_2_subclonal</td>\n",
       "      <td>369</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRMA_3 shared</td>\n",
       "      <td>407</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  A[C>A]A  A[C>A]C  A[C>A]G  A[C>A]T  A[C>G]A  A[C>G]C  \\\n",
       "0     BRMA_1 clonal       11       10        4       11       16        5   \n",
       "1  BRMA_2_subclonal      369       19        3       26       17        6   \n",
       "2     BRMA_3 shared      407       27        3       44       11        1   \n",
       "\n",
       "   A[C>G]G  A[C>G]T  A[C>T]A  ...  T[T>A]G  T[T>A]T  T[T>C]A  T[T>C]C  \\\n",
       "0        2        5       52  ...        2       15       10        3   \n",
       "1        7        9       25  ...       17       25        5        6   \n",
       "2        2       14       15  ...        5       11        6        8   \n",
       "\n",
       "   T[T>C]G  T[T>C]T  T[T>G]A  T[T>G]C  T[T>G]G  T[T>G]T  \n",
       "0        9       17        6        3        3        9  \n",
       "1       14       15        6        3        5        8  \n",
       "2        2        8        3        0        4        6  \n",
       "\n",
       "[3 rows x 97 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>A[C&gt;A]A</th>\n",
       "      <th>A[C&gt;A]C</th>\n",
       "      <th>A[C&gt;A]G</th>\n",
       "      <th>A[C&gt;A]T</th>\n",
       "      <th>A[C&gt;G]A</th>\n",
       "      <th>A[C&gt;G]C</th>\n",
       "      <th>A[C&gt;G]G</th>\n",
       "      <th>A[C&gt;G]T</th>\n",
       "      <th>A[C&gt;T]A</th>\n",
       "      <th>...</th>\n",
       "      <th>T[T&gt;A]G</th>\n",
       "      <th>T[T&gt;A]T</th>\n",
       "      <th>T[T&gt;C]A</th>\n",
       "      <th>T[T&gt;C]C</th>\n",
       "      <th>T[T&gt;C]G</th>\n",
       "      <th>T[T&gt;C]T</th>\n",
       "      <th>T[T&gt;G]A</th>\n",
       "      <th>T[T&gt;G]C</th>\n",
       "      <th>T[T&gt;G]G</th>\n",
       "      <th>T[T&gt;G]T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRMA_1 clonal</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRMA_2 private_lowfreq</td>\n",
       "      <td>295</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>53</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>120</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>88</td>\n",
       "      <td>19</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>138</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRMA_3 private</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Unnamed: 0  A[C>A]A  A[C>A]C  A[C>A]G  A[C>A]T  A[C>G]A  \\\n",
       "0           BRMA_1 clonal       11       10        4       11       16   \n",
       "1  BRMA_2 private_lowfreq      295       35       11       50       53   \n",
       "2          BRMA_3 private       21       10        2       11        2   \n",
       "\n",
       "   A[C>G]C  A[C>G]G  A[C>G]T  A[C>T]A  ...  T[T>A]G  T[T>A]T  T[T>C]A  \\\n",
       "0        5        2        5       52  ...        2       15       10   \n",
       "1       24       17       26      120  ...       26       88       19   \n",
       "2        1        5        2       12  ...       10       24        9   \n",
       "\n",
       "   T[T>C]C  T[T>C]G  T[T>C]T  T[T>G]A  T[T>G]C  T[T>G]G  T[T>G]T  \n",
       "0        3        9       17        6        3        3        9  \n",
       "1       37       38      138       15       17       26       86  \n",
       "2        3        3        8        0        3        6        7  \n",
       "\n",
       "[3 rows x 97 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2 = pd.read_csv(\"/Users/riccardobergamin/sample_2.csv\")\n",
    "X_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_1 = X_1.values[:,1:]\n",
    "c_2 = X_2.values[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_1 = torch.tensor(np.array(c_1,dtype=float))\n",
    "M_2 = torch.tensor(np.array(c_2,dtype=float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 96])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 96])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_1= M_1.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_2 = M_2.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1334.,    0.,    0.],\n",
       "        [   0., 4008., 4008.],\n",
       "        [   0., 4008., 4401.]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct overlap matrix\n",
    "\n",
    "\n",
    "# example 1 \n",
    "\n",
    "num_samples = 3\n",
    "    \n",
    "t_0 = torch.sum(M_1[0,])\n",
    "    \n",
    "t_1 = torch.sum(M_1[1,])\n",
    "    \n",
    "t_2 = torch.sum(M_1[2,])\n",
    "    \n",
    "overlaps_0 = torch.tensor([t_0,0,0])\n",
    "    \n",
    "overlaps_1 = torch.tensor([0,t_1,min(t_1,t_2)])\n",
    "    \n",
    "overlaps_3 = torch.tensor([0,min(t_1,t_2),t_2])\n",
    "    \n",
    "overlaps = torch.cat((overlaps_0,overlaps_1,overlaps_3),0).reshape(3,3)\n",
    "    \n",
    "overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look for chemo\n",
    "K = 1\n",
    "\n",
    "#aging signature\n",
    "\n",
    "aging = pd.read_csv(\"/Users/riccardobergamin/beta_aging.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = aging.values[:,1:]\n",
    "beta_aging = torch.tensor(np.array(b,dtype=float))\n",
    "beta_aging = beta_aging.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 96])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_aging.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= 5078.93505859375\n",
      "loss= 1625.1857147216797\n",
      "loss= 751.9563446044922\n",
      "loss= 651.204704284668\n",
      "loss= 613.8875198364258\n",
      "loss= 596.5420074462891\n",
      "loss= 581.9448852539062\n",
      "loss= 580.1666641235352\n",
      "loss= 578.6744689941406\n",
      "loss= 578.0636215209961\n",
      "loss= 577.892692565918\n",
      "loss= 577.7688140869141\n",
      "loss= 577.7285232543945\n",
      "loss= 577.710807800293\n",
      "loss= 577.6980667114258\n",
      "loss= 577.695686340332\n",
      "loss= 577.6925506591797\n",
      "loss= 577.6919937133789\n",
      "loss= 577.6896057128906\n",
      "loss= 577.6900024414062\n",
      "loss= 577.6881866455078\n",
      "loss= 577.6864929199219\n",
      "loss= 577.6855010986328\n",
      "loss= 577.6854934692383\n",
      "loss= 577.6844177246094\n",
      "loss= 577.6836547851562\n",
      "loss= 577.6813049316406\n",
      "loss= 577.6808013916016\n",
      "loss= 577.6819534301758\n",
      "loss= 577.6793365478516\n",
      "loss= 577.6801834106445\n",
      "loss= 577.6797027587891\n",
      "loss= 577.6789245605469\n",
      "loss= 577.6774444580078\n",
      "loss= 577.6763458251953\n",
      "loss= 577.6747741699219\n",
      "loss= 577.676513671875\n",
      "loss= 577.6734771728516\n",
      "loss= 577.6742248535156\n",
      "loss= 577.6744842529297\n",
      "loss= 577.6720199584961\n",
      "loss= 577.6728363037109\n",
      "loss= 577.6716613769531\n",
      "loss= 577.6712188720703\n",
      "loss= 577.6705322265625\n",
      "loss= 577.6698760986328\n",
      "loss= 577.6693267822266\n",
      "loss= 577.669303894043\n",
      "loss= 577.6694793701172\n",
      "loss= 577.6674499511719\n",
      "final loss= 577.6672973632812\n"
     ]
    }
   ],
   "source": [
    "inference(model,guide,M_1,K,overlaps,beta_aging,lr=0.05,num_steps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-152-331415585ada>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  parameters.update({key : torch.tensor(pyro.param(key))})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AutoDelta.activities': tensor([ 5.7040,  6.9274,  0.2099, -0.0809, -0.0950,  8.3182, -0.0810, -0.0951,\n",
       "          8.3662]),\n",
       " 'AutoDelta.extra_signal': tensor([[9.2316e-02, 5.4700e-03, 7.1349e-04, 8.3268e-03, 3.3288e-03, 8.3123e-04,\n",
       "          1.0703e-03, 2.7337e-03, 4.7463e-03, 1.3034e-03, 8.7221e-03, 2.7296e-03,\n",
       "          5.4711e-03, 4.4006e-03, 4.6377e-03, 6.3054e-03, 3.4397e-03, 1.1860e-03,\n",
       "          2.8468e-03, 2.9645e-03, 7.1298e-04, 1.1834e-04, 4.7410e-04, 4.7481e-04,\n",
       "          3.3860e-01, 3.0915e-03, 2.8541e-03, 9.0417e-03, 1.4261e-03, 1.1876e-03,\n",
       "          4.7523e-04, 2.2582e-03, 1.6611e-03, 1.8994e-03, 6.9719e-03, 3.3267e-03,\n",
       "          2.8546e-03, 1.6644e-03, 2.2592e-03, 3.8060e-03, 1.7815e-03, 2.3765e-03,\n",
       "          2.1367e-03, 1.6622e-03, 4.7526e-04, 5.9371e-04, 1.1882e-03, 8.3113e-04,\n",
       "          1.5562e-01, 1.2014e-02, 9.7540e-03, 3.3551e-02, 3.4489e-03, 1.3074e-03,\n",
       "          3.5655e-04, 2.4969e-03, 5.1109e-03, 1.6609e-03, 5.6598e-03, 2.6137e-03,\n",
       "          6.8997e-03, 7.7312e-03, 8.3263e-03, 3.3318e-03, 3.6848e-03, 1.3064e-03,\n",
       "          3.9222e-03, 2.4954e-03, 1.0702e-03, 3.5648e-04, 1.3073e-03, 1.5459e-03,\n",
       "          9.0174e-02, 4.0420e-03, 2.1409e-03, 1.8675e-02, 2.6155e-03, 1.4260e-03,\n",
       "          8.3248e-04, 3.8041e-03, 5.5866e-03, 3.4452e-03, 4.0172e-03, 4.8731e-03,\n",
       "          2.7332e-03, 1.6646e-03, 2.6160e-03, 4.2808e-03, 1.3046e-03, 1.6626e-03,\n",
       "          1.9005e-03, 2.7312e-03, 1.0696e-03, 3.5541e-04, 1.0690e-03, 1.6626e-03]])}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters={}\n",
    "        \n",
    "for key in pyro.get_param_store().get_all_param_names() :\n",
    "    \n",
    "             parameters.update({key : torch.tensor(pyro.param(key))})\n",
    "        \n",
    "parameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.0007e+02, 1.0199e+03, 1.2335e+00],\n",
      "        [9.2226e-01, 9.0934e-01, 4.0978e+03],\n",
      "        [9.2217e-01, 9.0925e-01, 4.2992e+03]])\n",
      "tensor([[9.2316e-02, 5.4700e-03, 7.1349e-04, 8.3268e-03, 3.3288e-03, 8.3123e-04,\n",
      "         1.0703e-03, 2.7337e-03, 4.7463e-03, 1.3034e-03, 8.7221e-03, 2.7296e-03,\n",
      "         5.4711e-03, 4.4006e-03, 4.6377e-03, 6.3054e-03, 3.4397e-03, 1.1860e-03,\n",
      "         2.8468e-03, 2.9645e-03, 7.1298e-04, 1.1834e-04, 4.7410e-04, 4.7481e-04,\n",
      "         3.3860e-01, 3.0915e-03, 2.8541e-03, 9.0417e-03, 1.4261e-03, 1.1876e-03,\n",
      "         4.7523e-04, 2.2582e-03, 1.6611e-03, 1.8994e-03, 6.9719e-03, 3.3267e-03,\n",
      "         2.8546e-03, 1.6644e-03, 2.2592e-03, 3.8060e-03, 1.7815e-03, 2.3765e-03,\n",
      "         2.1367e-03, 1.6622e-03, 4.7526e-04, 5.9371e-04, 1.1882e-03, 8.3113e-04,\n",
      "         1.5562e-01, 1.2014e-02, 9.7540e-03, 3.3551e-02, 3.4489e-03, 1.3074e-03,\n",
      "         3.5655e-04, 2.4969e-03, 5.1109e-03, 1.6609e-03, 5.6598e-03, 2.6137e-03,\n",
      "         6.8997e-03, 7.7312e-03, 8.3263e-03, 3.3318e-03, 3.6848e-03, 1.3064e-03,\n",
      "         3.9222e-03, 2.4954e-03, 1.0702e-03, 3.5648e-04, 1.3073e-03, 1.5459e-03,\n",
      "         9.0174e-02, 4.0420e-03, 2.1409e-03, 1.8675e-02, 2.6155e-03, 1.4260e-03,\n",
      "         8.3248e-04, 3.8041e-03, 5.5866e-03, 3.4452e-03, 4.0172e-03, 4.8731e-03,\n",
      "         2.7332e-03, 1.6646e-03, 2.6160e-03, 4.2808e-03, 1.3046e-03, 1.6626e-03,\n",
      "         1.9005e-03, 2.7312e-03, 1.0696e-03, 3.5541e-04, 1.0690e-03, 1.6626e-03]])\n"
     ]
    }
   ],
   "source": [
    "alpha = torch.exp(parameters[\"AutoDelta.activities\"]).reshape(num_samples,K+2) \n",
    "beta_chemo = parameters[\"AutoDelta.extra_signal\"]\n",
    "print(alpha)\n",
    "print(beta_chemo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1334.,    0.,    0.],\n",
       "        [   0., 5510.,  857.],\n",
       "        [   0.,  857.,  857.]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example 2 \n",
    "\n",
    "num_samples = 3\n",
    "    \n",
    "t_0 = torch.sum(M_2[0,])\n",
    "    \n",
    "t_1 = torch.sum(M_2[1,])\n",
    "    \n",
    "t_2 = torch.sum(M_2[2,])\n",
    "    \n",
    "overlaps_0 = torch.tensor([t_0,0,0])\n",
    "    \n",
    "overlaps_1 = torch.tensor([0,t_1,min(t_1,t_2)])\n",
    "    \n",
    "overlaps_3 = torch.tensor([0,min(t_1,t_2),t_2])\n",
    "    \n",
    "overlaps = torch.cat((overlaps_0,overlaps_1,overlaps_3),0).reshape(3,3)\n",
    "    \n",
    "overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= 5967.743637084961\n",
      "loss= 2672.9450073242188\n",
      "loss= 1461.6221313476562\n",
      "loss= 1242.6842651367188\n",
      "loss= 1215.05322265625\n",
      "loss= 1199.2042846679688\n",
      "loss= 1187.131103515625\n",
      "loss= 1182.2289428710938\n",
      "loss= 1181.5432739257812\n",
      "loss= 1181.3078002929688\n",
      "loss= 1181.0877075195312\n",
      "loss= 1181.0213623046875\n",
      "loss= 1181.01708984375\n",
      "loss= 1181.0081787109375\n",
      "loss= 1181.0043334960938\n",
      "loss= 1181.0032348632812\n",
      "loss= 1181.002685546875\n",
      "loss= 1181.0025634765625\n",
      "loss= 1181.001953125\n",
      "loss= 1181.0023803710938\n",
      "loss= 1181.001708984375\n",
      "loss= 1181.0014038085938\n",
      "loss= 1181.0013427734375\n",
      "loss= 1181.00146484375\n",
      "loss= 1181.00048828125\n",
      "loss= 1181.0008544921875\n",
      "loss= 1181.0\n",
      "loss= 1181.000244140625\n",
      "loss= 1181.0006713867188\n",
      "loss= 1181.0003662109375\n",
      "loss= 1181.0001831054688\n",
      "loss= 1180.9999389648438\n",
      "loss= 1181.0001220703125\n",
      "loss= 1181.0001831054688\n",
      "loss= 1180.9998168945312\n",
      "loss= 1181.0001831054688\n",
      "loss= 1180.9999389648438\n",
      "loss= 1180.9998168945312\n",
      "loss= 1180.9999389648438\n",
      "loss= 1180.9996948242188\n",
      "loss= 1180.99951171875\n",
      "loss= 1181.000244140625\n",
      "loss= 1181.0309448242188\n",
      "loss= 1181.0247192382812\n",
      "loss= 1181.007568359375\n",
      "loss= 1181.0029296875\n",
      "loss= 1181.0010986328125\n",
      "loss= 1181.0004272460938\n",
      "loss= 1181.0001831054688\n",
      "loss= 1180.9995727539062\n",
      "loss= 1180.9998168945312\n",
      "loss= 1181.0\n",
      "loss= 1181.0\n",
      "loss= 1180.9999389648438\n",
      "loss= 1180.999267578125\n",
      "loss= 1180.9992065429688\n",
      "loss= 1181.0\n",
      "loss= 1180.9994506835938\n",
      "loss= 1180.9999389648438\n",
      "loss= 1180.99951171875\n",
      "loss= 1180.999755859375\n",
      "loss= 1180.99951171875\n",
      "loss= 1181.0001220703125\n",
      "loss= 1180.9996948242188\n",
      "loss= 1180.9994506835938\n",
      "loss= 1180.9998779296875\n",
      "loss= 1180.999755859375\n",
      "loss= 1181.0000610351562\n",
      "loss= 1181.0000610351562\n",
      "loss= 1180.9999389648438\n",
      "loss= 1181.000244140625\n",
      "loss= 1181.0135498046875\n",
      "loss= 1181.0092163085938\n",
      "loss= 1180.9994506835938\n",
      "loss= 1181.0005493164062\n",
      "loss= 1181.0000610351562\n",
      "loss= 1180.9994506835938\n",
      "loss= 1181.0\n",
      "loss= 1181.0001220703125\n",
      "loss= 1180.999267578125\n",
      "final loss= 1181.0\n"
     ]
    }
   ],
   "source": [
    "inference(model,guide,M_2,K,overlaps,beta_aging,lr=0.05,num_steps=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-156-a35674ae45ca>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  parameters.update({key : torch.tensor(pyro.param(key))})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AutoDelta.activities': tensor([ 5.7038,  6.9276,  0.1446,  0.1300, -0.1729,  8.5091,  0.1302, -0.1733,\n",
       "          7.2410]),\n",
       " 'AutoDelta.extra_signal': tensor([[0.0497, 0.0071, 0.0020, 0.0096, 0.0086, 0.0039, 0.0035, 0.0044, 0.0207,\n",
       "          0.0068, 0.0225, 0.0102, 0.0165, 0.0072, 0.0071, 0.0209, 0.0231, 0.0046,\n",
       "          0.0129, 0.0096, 0.0046, 0.0014, 0.0030, 0.0025, 0.1460, 0.0050, 0.0030,\n",
       "          0.0086, 0.0022, 0.0027, 0.0022, 0.0028, 0.0071, 0.0061, 0.0180, 0.0113,\n",
       "          0.0101, 0.0086, 0.0116, 0.0099, 0.0055, 0.0055, 0.0077, 0.0085, 0.0009,\n",
       "          0.0020, 0.0022, 0.0025, 0.0621, 0.0086, 0.0052, 0.0157, 0.0038, 0.0011,\n",
       "          0.0016, 0.0027, 0.0074, 0.0060, 0.0170, 0.0083, 0.0110, 0.0093, 0.0135,\n",
       "          0.0072, 0.0093, 0.0046, 0.0116, 0.0071, 0.0013, 0.0013, 0.0036, 0.0020,\n",
       "          0.0361, 0.0072, 0.0025, 0.0145, 0.0064, 0.0058, 0.0020, 0.0124, 0.0082,\n",
       "          0.0091, 0.0100, 0.0118, 0.0091, 0.0028, 0.0057, 0.0176, 0.0044, 0.0063,\n",
       "          0.0064, 0.0229, 0.0024, 0.0031, 0.0050, 0.0146]])}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters={}\n",
    "        \n",
    "for key in pyro.get_param_store().get_all_param_names() :\n",
    "    \n",
    "             parameters.update({key : torch.tensor(pyro.param(key))})\n",
    "        \n",
    "parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.0000e+02, 1.0201e+03, 1.1556e+00],\n",
      "        [1.1388e+00, 8.4121e-01, 4.9597e+03],\n",
      "        [1.1391e+00, 8.4090e-01, 1.3955e+03]])\n",
      "tensor([[0.0497, 0.0071, 0.0020, 0.0096, 0.0086, 0.0039, 0.0035, 0.0044, 0.0207,\n",
      "         0.0068, 0.0225, 0.0102, 0.0165, 0.0072, 0.0071, 0.0209, 0.0231, 0.0046,\n",
      "         0.0129, 0.0096, 0.0046, 0.0014, 0.0030, 0.0025, 0.1460, 0.0050, 0.0030,\n",
      "         0.0086, 0.0022, 0.0027, 0.0022, 0.0028, 0.0071, 0.0061, 0.0180, 0.0113,\n",
      "         0.0101, 0.0086, 0.0116, 0.0099, 0.0055, 0.0055, 0.0077, 0.0085, 0.0009,\n",
      "         0.0020, 0.0022, 0.0025, 0.0621, 0.0086, 0.0052, 0.0157, 0.0038, 0.0011,\n",
      "         0.0016, 0.0027, 0.0074, 0.0060, 0.0170, 0.0083, 0.0110, 0.0093, 0.0135,\n",
      "         0.0072, 0.0093, 0.0046, 0.0116, 0.0071, 0.0013, 0.0013, 0.0036, 0.0020,\n",
      "         0.0361, 0.0072, 0.0025, 0.0145, 0.0064, 0.0058, 0.0020, 0.0124, 0.0082,\n",
      "         0.0091, 0.0100, 0.0118, 0.0091, 0.0028, 0.0057, 0.0176, 0.0044, 0.0063,\n",
      "         0.0064, 0.0229, 0.0024, 0.0031, 0.0050, 0.0146]])\n"
     ]
    }
   ],
   "source": [
    "alpha = torch.exp(parameters[\"AutoDelta.activities\"]).reshape(num_samples,K+2) \n",
    "beta_chemo = parameters[\"AutoDelta.extra_signal\"]\n",
    "print(alpha)\n",
    "print(beta_chemo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
